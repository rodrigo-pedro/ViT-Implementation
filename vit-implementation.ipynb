{"cells":[{"cell_type":"markdown","metadata":{"id":"aWS6MPLsEfja"},"source":["## Code"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:03:58.860502Z","iopub.status.busy":"2024-02-09T12:03:58.860235Z"},"id":"XXhySJIuEfja","outputId":"e253e99e-304d-420e-cc67-d51453bead42","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: einops in ./.venv/lib/python3.10/site-packages (0.7.0)\n","Note: you may need to restart the kernel to use updated packages.\n","The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["%pip install einops\n","%load_ext tensorboard\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import default_collate\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.transforms import v2\n","import matplotlib.pyplot as plt\n","import einops\n","from einops.layers.torch import Rearrange\n","from tqdm import tqdm\n","\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"EBIHAVUEEfjb","trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.0):\n","        super().__init__()\n","        self.seq = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.seq(x)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"b16F9h52Efjb","trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, dim, heads, dropout=0.0):\n","        super().__init__()\n","\n","        self.dim = dim # size of embeddings\n","        self.heads = heads\n","\n","        self.head_len = int(self.dim / self.heads)\n","        self.norm_scale = self.head_len ** -0.5 # divide by sqrt of query size during normalization\n","\n","        # pytorch automatically handles the remaining dimensions by expansion. It is equivalent of the neural network receiving one word embedding as input at a time, but vectorized.\n","        self.q_linear = nn.Linear(self.dim, self.dim, bias = False)\n","        self.k_linear = nn.Linear(self.dim , self.dim, bias = False)\n","        self.v_linear = nn.Linear(self.dim, self.dim, bias = False)\n","\n","        # dim is seq (because will be applied after q_dot_k)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # input and output is the same. Could be different if we increased the head_len as a parameter instead of being dim/num_heads.\n","        self.dense = nn.Sequential(\n","          nn.Linear(self.dim, self.dim),\n","          nn.Dropout(dropout)\n","        )\n","\n","\n","    def forward(self, key, query, value):\n","        # pass through linear layers\n","        q = self.q_linear(query)\n","        k = self.k_linear(key)\n","        v = self.v_linear(value)\n","\n","        # split heads and reshape. seq, head_len is a 2d matrix that is going to be multiplied. The other two dimensions are static.\n","        q = einops.rearrange(q, 'b seq (head head_len) -> b head seq head_len', head = self.heads)\n","        v = einops.rearrange(v, 'b seq (head head_len) -> b head seq head_len', head = self.heads)\n","        # transpose k for matmul. Just change the last two dimensions around because we need seq,head_len * head_len,seq\n","        k = einops.rearrange(k, 'b seq (head head_len) -> b head head_len seq', head = self.heads)\n","\n","        # matmul between q and k\n","        q_dot_k = torch.matmul(q,k)\n","\n","        # divide result by sqrt of head len\n","        q_dot_k *= self.norm_scale\n","\n","        # softmax of q_dot_k\n","        attention_scores = self.softmax(q_dot_k)\n","\n","        # apply dropout\n","        attention_scores = self.dropout(attention_scores)\n","\n","        # matmul by value to obtain final result\n","        result = torch.matmul(attention_scores, v)\n","\n","        # concatenate all heads. We get back the entire dim size\n","        result_concat = einops.rearrange(result, 'b head seq head_len -> b seq (head head_len)')\n","\n","        # pass through final dense layer\n","        out = self.dense(result_concat)\n","\n","        return out\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"UOBQuEPiEfjb","trusted":true},"outputs":[],"source":["class TransformerEncoder(nn.Module):\n","    def __init__(self, dim, heads, depth, mlp_hidden_dim, dropout=0.0):\n","        super().__init__()\n","\n","        self.list = nn.ModuleList([])\n","        for _ in range(depth):\n","            entry = nn.ModuleList([\n","                nn.LayerNorm(dim),\n","                MultiHeadAttention(dim, heads, dropout=dropout),\n","                nn.LayerNorm(dim),\n","                MLP(dim, mlp_hidden_dim, dropout=dropout)\n","            ])\n","            self.list.append(entry)\n","\n","    def forward(self, x):\n","        for norm1, attention, norm2, mlp in self.list: # type: ignore\n","            x_res = x # deep copy shouldn't be need\n","            x = norm1(x)\n","            x = attention(x, x, x) + x_res\n","\n","            x_res = x\n","            x = norm2(x)\n","            x = mlp(x) + x_res\n","        return x\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"FRK_fh2NEfjb","trusted":true},"outputs":[],"source":["class CreatePatches(nn.Module):\n","    def __init__(self, patch_size, num_channels, emb_dim):\n","        super().__init__()\n","\n","        self.flatten_and_project = nn.Sequential(\n","            # from (b c h w) to (b num_patches patch_data)\n","            # the (num_patches_h p1) means that we get i patches of size p1 across the h axis, where num_patches_h takes the value i\n","            # the same goes for (num_patches_w p2), where num_patches_w takes the value j\n","            # therefore, (num_patches_h num_patches_w) is i*j = num_patches\n","            Rearrange('b c (num_patches_h p1) (num_patches_w p2) -> b (num_patches_h num_patches_w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),\n","            # takes in patch_size*patch_size*num_channels, outputs a emb_dim vector\n","            nn.Linear(patch_size*patch_size*num_channels, emb_dim)\n","        )\n","\n","    def forward(self, x):\n","        return self.flatten_and_project(x)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"1cVRvtkkEfjb","trusted":true},"outputs":[],"source":["class ViT(nn.Module):\n","    def __init__(self, img_size, patch_size, num_channels, emb_dim, heads, depth, transformer_mlp_hidden_dim, num_classes, dropout=0.0):\n","        super().__init__()\n","        # assuming images are square\n","        assert img_size % patch_size == 0, 'img_size must be divisible by patch_size'\n","\n","        self.num_patches = (img_size // patch_size) ** 2\n","\n","        self.create_patches = CreatePatches(patch_size=patch_size, num_channels=num_channels, emb_dim=emb_dim)\n","\n","        # positional encoding - learned parameters\n","        # the first dimension is 1 for the batches. Broadcasting makes the pos_encoding the same for all batches\n","        self.pos_encoding = nn.Parameter(torch.randn(1, self.num_patches, emb_dim))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.transformer_encoder = TransformerEncoder(dim=emb_dim, heads=heads, depth=depth, mlp_hidden_dim=transformer_mlp_hidden_dim, dropout=dropout)\n","\n","        self.mlp_linear_head = nn.Sequential(\n","            nn.LayerNorm(emb_dim),\n","            nn.Linear(emb_dim, num_classes),\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.create_patches(x)\n","\n","        # positional encoding. Broadcasting adds same pos_encoding to all batches\n","        x += self.pos_encoding\n","\n","        x = self.dropout(x)\n","\n","        x = self.transformer_encoder(x)\n","\n","        # mean - average all embedding vectors to get a single vector\n","        # we don't use cls. Apparently average pool is be better\n","        # https://arxiv.org/pdf/2205.01580.pdf\n","        x = x.mean(dim=1)\n","\n","        x = self.mlp_linear_head(x)\n","\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"VUTN5JwyEfjb"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvrjUNTXhFmq","trusted":true},"outputs":[],"source":["%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["# Hyperparams\n","batch_size = 256\n","patch_size = 4\n","emb_dim = 256\n","heads = 8\n","depth = 8\n","mlp_hidden_dim = 256\n","epochs = 100\n","dropout = 0.1\n","lr = 3e-4\n","weight_decay = 0.0001\n","mixup_p = 0.0\n","flip_lr_p = 0.5\n","rand_aug_num_ops = 2\n","rand_aug_magnitude = 10"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"MT98vL3cEfjb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:13<00:00, 12935200.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/cifar-10-python.tar.gz to data\n"]}],"source":["train_transform = v2.Compose(\n","    [\n","        v2.PILToTensor(),\n","        v2.RandomCrop(32, padding=4),  # Adding RandomCrop here with padding\n","        v2.RandomHorizontalFlip(p=flip_lr_p),\n","        v2.RandAugment(num_ops=rand_aug_num_ops, magnitude=rand_aug_magnitude),\n","        v2.ToDtype(torch.float32, scale=True),\n","        v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    ]\n",")\n","\n","training_data = datasets.CIFAR10(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=train_transform,\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T03:04:53.859638Z","iopub.status.busy":"2024-02-09T03:04:53.859360Z","iopub.status.idle":"2024-02-09T03:05:17.077065Z","shell.execute_reply":"2024-02-09T03:05:17.075255Z","shell.execute_reply.started":"2024-02-09T03:04:53.859613Z"},"id":"xB3jFCEXEfjc","outputId":"344c67a1-4420-4dcf-8ec5-1788926fff4b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 of 100: 100%|██████████| 196/196 [00:57<00:00,  3.39batches/s, accuracy=0.2054, loss=2.107837]\n","Epoch 2 of 100: 100%|██████████| 196/196 [01:00<00:00,  3.25batches/s, accuracy=0.2858, loss=1.689123]\n","Epoch 3 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.18batches/s, accuracy=0.3569, loss=1.730898]\n","Epoch 4 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.18batches/s, accuracy=0.3915, loss=1.490305]\n","Epoch 5 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.01batches/s, accuracy=0.4229, loss=1.292164]\n","Epoch 6 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.04batches/s, accuracy=0.4413, loss=1.492599]\n","Epoch 7 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.15batches/s, accuracy=0.4584, loss=1.370872]\n","Epoch 8 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.06batches/s, accuracy=0.4753, loss=1.366273]\n","Epoch 9 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.11batches/s, accuracy=0.4912, loss=1.229915]\n","Epoch 10 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.07batches/s, accuracy=0.5044, loss=1.225187]\n","Epoch 11 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.17batches/s, accuracy=0.5200, loss=1.426128]\n","Epoch 12 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.12batches/s, accuracy=0.5281, loss=1.119011]\n","Epoch 13 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.02batches/s, accuracy=0.5388, loss=1.380757]\n","Epoch 14 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.14batches/s, accuracy=0.5519, loss=1.274918]\n","Epoch 15 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.13batches/s, accuracy=0.5608, loss=1.227491]\n","Epoch 16 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.08batches/s, accuracy=0.5740, loss=1.131206]\n","Epoch 17 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.01batches/s, accuracy=0.5796, loss=1.218969]\n","Epoch 18 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.08batches/s, accuracy=0.5929, loss=1.016217]\n","Epoch 19 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.16batches/s, accuracy=0.5967, loss=1.090275]\n","Epoch 20 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.08batches/s, accuracy=0.6018, loss=1.082909]\n","Epoch 21 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.05batches/s, accuracy=0.6154, loss=1.115093]\n","Epoch 22 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.99batches/s, accuracy=0.6160, loss=1.152717]\n","Epoch 23 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.99batches/s, accuracy=0.6242, loss=1.092134]\n","Epoch 24 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.11batches/s, accuracy=0.6302, loss=0.987868]\n","Epoch 25 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.03batches/s, accuracy=0.6341, loss=1.015458]\n","Epoch 26 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.07batches/s, accuracy=0.6365, loss=0.981464]\n","Epoch 27 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.99batches/s, accuracy=0.6428, loss=1.208762]\n","Epoch 28 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.97batches/s, accuracy=0.6470, loss=0.949687]\n","Epoch 29 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.11batches/s, accuracy=0.6498, loss=1.074744]\n","Epoch 30 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.15batches/s, accuracy=0.6520, loss=0.908437]\n","Epoch 31 of 100: 100%|██████████| 196/196 [01:09<00:00,  2.84batches/s, accuracy=0.6590, loss=0.953039]\n","Epoch 32 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.05batches/s, accuracy=0.6612, loss=1.077405]\n","Epoch 33 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.06batches/s, accuracy=0.6627, loss=0.868360]\n","Epoch 34 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.00batches/s, accuracy=0.6665, loss=0.906549]\n","Epoch 35 of 100: 100%|██████████| 196/196 [01:06<00:00,  2.93batches/s, accuracy=0.6709, loss=0.846767]\n","Epoch 36 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.04batches/s, accuracy=0.6731, loss=1.311542]\n","Epoch 37 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.12batches/s, accuracy=0.6737, loss=0.900060]\n","Epoch 38 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.06batches/s, accuracy=0.6788, loss=0.859612]\n","Epoch 39 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.18batches/s, accuracy=0.6815, loss=1.023807]\n","Epoch 40 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.06batches/s, accuracy=0.6842, loss=0.884361]\n","Epoch 41 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.09batches/s, accuracy=0.6877, loss=0.717689]\n","Epoch 42 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.98batches/s, accuracy=0.6876, loss=1.010218]\n","Epoch 43 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.15batches/s, accuracy=0.6923, loss=0.939635]\n","Epoch 44 of 100: 100%|██████████| 196/196 [01:06<00:00,  2.96batches/s, accuracy=0.6908, loss=1.008273]\n","Epoch 45 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.06batches/s, accuracy=0.6937, loss=0.826672]\n","Epoch 46 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.00batches/s, accuracy=0.6971, loss=0.703356]\n","Epoch 47 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.04batches/s, accuracy=0.7015, loss=0.818256]\n","Epoch 48 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.00batches/s, accuracy=0.7058, loss=0.982900]\n","Epoch 49 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.08batches/s, accuracy=0.7045, loss=0.738708]\n","Epoch 50 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.03batches/s, accuracy=0.7075, loss=0.811712]\n","Epoch 51 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.10batches/s, accuracy=0.7103, loss=0.665054]\n","Epoch 52 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.09batches/s, accuracy=0.7130, loss=0.900163]\n","Epoch 53 of 100: 100%|██████████| 196/196 [00:58<00:00,  3.35batches/s, accuracy=0.7131, loss=0.725833]\n","Epoch 54 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.06batches/s, accuracy=0.7163, loss=0.743871]\n","Epoch 55 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.02batches/s, accuracy=0.7213, loss=0.704379]\n","Epoch 56 of 100: 100%|██████████| 196/196 [01:06<00:00,  2.94batches/s, accuracy=0.7207, loss=0.692582]\n","Epoch 57 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.01batches/s, accuracy=0.7216, loss=0.820611]\n","Epoch 58 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.03batches/s, accuracy=0.7261, loss=0.792905]\n","Epoch 59 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.98batches/s, accuracy=0.7286, loss=0.798584]\n","Epoch 60 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.17batches/s, accuracy=0.7298, loss=0.854482]\n","Epoch 61 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.08batches/s, accuracy=0.7325, loss=0.766525]\n","Epoch 62 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.16batches/s, accuracy=0.7368, loss=1.029887]\n","Epoch 63 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.10batches/s, accuracy=0.7351, loss=0.689265]\n","Epoch 64 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.01batches/s, accuracy=0.7360, loss=0.678619]\n","Epoch 65 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.06batches/s, accuracy=0.7373, loss=0.699345]\n","Epoch 66 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.21batches/s, accuracy=0.7386, loss=0.483733]\n","Epoch 67 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.19batches/s, accuracy=0.7416, loss=0.846502]\n","Epoch 68 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.09batches/s, accuracy=0.7475, loss=0.591953]\n","Epoch 69 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.19batches/s, accuracy=0.7478, loss=1.038619]\n","Epoch 70 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.09batches/s, accuracy=0.7484, loss=0.772098]\n","Epoch 71 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.01batches/s, accuracy=0.7494, loss=0.741055]\n","Epoch 72 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.03batches/s, accuracy=0.7511, loss=0.819258]\n","Epoch 73 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.97batches/s, accuracy=0.7516, loss=0.643376]\n","Epoch 74 of 100: 100%|██████████| 196/196 [01:07<00:00,  2.92batches/s, accuracy=0.7560, loss=0.781399]\n","Epoch 75 of 100: 100%|██████████| 196/196 [01:06<00:00,  2.93batches/s, accuracy=0.7560, loss=0.733566]\n","Epoch 76 of 100: 100%|██████████| 196/196 [01:06<00:00,  2.94batches/s, accuracy=0.7579, loss=0.843683]\n","Epoch 77 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.04batches/s, accuracy=0.7600, loss=0.657184]\n","Epoch 78 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.04batches/s, accuracy=0.7638, loss=0.917569]\n","Epoch 79 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.10batches/s, accuracy=0.7651, loss=0.775678]\n","Epoch 80 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.10batches/s, accuracy=0.7677, loss=0.583084]\n","Epoch 81 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.15batches/s, accuracy=0.7725, loss=0.582826]\n","Epoch 82 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.09batches/s, accuracy=0.7724, loss=0.471366]\n","Epoch 83 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.18batches/s, accuracy=0.7725, loss=0.675476]\n","Epoch 84 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.10batches/s, accuracy=0.7744, loss=0.511622]\n","Epoch 85 of 100: 100%|██████████| 196/196 [01:01<00:00,  3.20batches/s, accuracy=0.7793, loss=0.668798]\n","Epoch 86 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.07batches/s, accuracy=0.7785, loss=0.689095]\n","Epoch 87 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.16batches/s, accuracy=0.7803, loss=0.728129]\n","Epoch 88 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.10batches/s, accuracy=0.7820, loss=0.691403]\n","Epoch 89 of 100: 100%|██████████| 196/196 [01:05<00:00,  2.99batches/s, accuracy=0.7832, loss=0.528488]\n","Epoch 90 of 100: 100%|██████████| 196/196 [01:05<00:00,  3.01batches/s, accuracy=0.7859, loss=0.839212]\n","Epoch 91 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.09batches/s, accuracy=0.7869, loss=0.580844]\n","Epoch 92 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.08batches/s, accuracy=0.7872, loss=0.549740]\n","Epoch 93 of 100: 100%|██████████| 196/196 [01:02<00:00,  3.13batches/s, accuracy=0.7909, loss=0.667166]\n","Epoch 94 of 100: 100%|██████████| 196/196 [01:04<00:00,  3.06batches/s, accuracy=0.7916, loss=0.643954]\n","Epoch 95 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.11batches/s, accuracy=0.7913, loss=0.515338]\n","Epoch 96 of 100: 100%|██████████| 196/196 [00:59<00:00,  3.29batches/s, accuracy=0.7956, loss=0.613827]\n","Epoch 97 of 100: 100%|██████████| 196/196 [01:06<00:00,  2.93batches/s, accuracy=0.7951, loss=0.704803]\n","Epoch 98 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.07batches/s, accuracy=0.7956, loss=0.546184]\n","Epoch 99 of 100: 100%|██████████| 196/196 [01:06<00:00,  2.95batches/s, accuracy=0.7999, loss=0.794554]\n","Epoch 100 of 100: 100%|██████████| 196/196 [01:03<00:00,  3.10batches/s, accuracy=0.7973, loss=0.532935]\n"]}],"source":["num_channels, img_size, _ = training_data[0][0].shape  # get dimensions from the first image of the training dataset\n","num_classes = len(training_data.classes)\n","\n","writer = SummaryWriter()\n","\n","print(f\"Using device: {device}\")\n","\n","def collate_fn(batch):\n","    mixup = v2.MixUp(num_classes=num_classes)\n","    mixup = v2.RandomApply(torch.nn.ModuleList([mixup]), p=mixup_p)\n","    return mixup(*default_collate(batch))\n","\n","train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","\n","vit = ViT(\n","    img_size=img_size,\n","    patch_size=patch_size,\n","    num_channels=num_channels,\n","    emb_dim=emb_dim,\n","    heads=heads,\n","    depth=depth,\n","    transformer_mlp_hidden_dim=mlp_hidden_dim,\n","    num_classes=num_classes,\n","    dropout=dropout\n",").to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(vit.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","size = len(train_dataloader.dataset)\n","\n","vit.train()\n","for epoch in range(1, epochs+1):\n","    correct = 0\n","    total_samples = 0\n","    with tqdm(train_dataloader, unit=\"batches\") as pbar:\n","        for batch, (X, y) in enumerate(pbar):\n","            pbar.set_description(f\"Epoch {epoch} of {epochs}\")\n","\n","            X, y = X.to(device), y.to(device)\n","\n","            pred = vit(X)\n","\n","            # From the pytorch CrossEntropyLoss documentation:\n","            # \"The performance of this criterion is generally better when target contains class indices, as this allows for optimized computation.\n","            # Consider providing target as class probabilities only when a single class label per minibatch item is too restrictive.\"\n","            # Therefore, we convert to one-hot only if mixup is used.\n","            if mixup_p > 0.:\n","                y = torch.nn.functional.one_hot(y, num_classes=num_classes)\n","\n","            loss = loss_fn(pred, y)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            if mixup_p > 0.:\n","                correct += (pred.argmax(1) == y.argmax(1)).sum().item()\n","            else:\n","                correct += (pred.argmax(1) == y).sum().item()\n","\n","            total_samples += y.size(0) # batch size. Accounts for last batch which may be smaller\n","\n","            accuracy = correct / total_samples\n","\n","            pbar.set_postfix(loss=f\"{loss.item():>7f}\", accuracy=f\"{accuracy:.4f}\")\n","\n","            writer.add_scalar(\"Loss/train\", loss, epoch)\n","\n","    writer.add_scalar(\"Accuracy/train\", accuracy, epoch)  # Log epoch accuracy\n","\n","writer.close()"]},{"cell_type":"markdown","metadata":{"id":"qZs10yHTEfjc"},"source":["## Test"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.status.busy":"2024-02-09T03:05:17.078542Z","iopub.status.idle":"2024-02-09T03:05:17.078891Z","shell.execute_reply":"2024-02-09T03:05:17.078736Z","shell.execute_reply.started":"2024-02-09T03:05:17.078720Z"},"id":"qWvVhszrEfjc","outputId":"bda38206-4408-4abe-ff34-5a6ff1f38bfb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 40/40 [00:03<00:00, 13.06batches/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 80.74%, Avg loss: 0.565995 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["test_transform = v2.Compose(\n","    [\n","        v2.PILToTensor(),\n","        v2.ToDtype(torch.float32, scale=True),\n","        v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    ]\n",")\n","\n","test_data = datasets.CIFAR10(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=test_transform,\n",")\n","\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","size = len(test_dataloader.dataset) # type: ignore\n","num_batches = len(test_dataloader)\n","test_loss = 0\n","correct = 0\n","\n","vit.eval()\n","with torch.no_grad():\n","    for X, y in tqdm(test_dataloader, unit=\"batches\"):\n","        X, y = X.to(device), y.to(device)\n","        pred = vit(X)\n","        test_loss += loss_fn(pred, y).item()\n","        correct += (pred.argmax(1) == y).sum().item()\n","\n","test_loss /= num_batches\n","correct /= size\n","\n","print(f\"Accuracy: {100*correct}%, Avg loss: {test_loss:>8f} \\n\")\n"]},{"cell_type":"markdown","metadata":{"id":"-R8ByOiHEfjc"},"source":["## Save model"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.status.busy":"2024-02-09T03:05:17.080747Z","iopub.status.idle":"2024-02-09T03:05:17.081281Z","shell.execute_reply":"2024-02-09T03:05:17.081055Z","shell.execute_reply.started":"2024-02-09T03:05:17.081032Z"},"id":"zjxU_ya_Efjc","trusted":true},"outputs":[],"source":["torch.save(vit, 'model.pth')"]},{"cell_type":"markdown","metadata":{"id":"Ly1T6uylEfjc"},"source":["## Load model"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.status.busy":"2024-02-09T03:05:17.082695Z","iopub.status.idle":"2024-02-09T03:05:17.083173Z","shell.execute_reply":"2024-02-09T03:05:17.082933Z","shell.execute_reply.started":"2024-02-09T03:05:17.082913Z"},"id":"5H_AWOZ_Efjd","trusted":true},"outputs":[],"source":["vit = torch.load('model.pth').to(device)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
